{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7758261",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, ast, json, math, shutil, random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1715773-14bd-4f04-8381-7b31f2e5a3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colors</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['#c5d70f', '#4dd70f', '#0fd749', '#0fd7c1']</td>\n",
       "      <td>Fresh greens with a vibrant twist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['#6837e6', '#d037e6', '#e63792', '#e64537']</td>\n",
       "      <td>Vibrant purples and fiery pinks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['#a5d67a', '#7ad686', '#7ad6bd', '#7ab8d6']</td>\n",
       "      <td>Fresh and cool summery greens and blues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['#28e744', '#28e7b7', '#28a4e7', '#2832e7']</td>\n",
       "      <td>Vivid greens and blues, fresh harmony.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['#d5171a', '#d58517', '#b2d517', '#40d517']</td>\n",
       "      <td>Vivid transition from red to green.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         colors  \\\n",
       "0  ['#c5d70f', '#4dd70f', '#0fd749', '#0fd7c1']   \n",
       "1  ['#6837e6', '#d037e6', '#e63792', '#e64537']   \n",
       "2  ['#a5d67a', '#7ad686', '#7ad6bd', '#7ab8d6']   \n",
       "3  ['#28e744', '#28e7b7', '#28a4e7', '#2832e7']   \n",
       "4  ['#d5171a', '#d58517', '#b2d517', '#40d517']   \n",
       "\n",
       "                                       resp  \n",
       "0        Fresh greens with a vibrant twist.  \n",
       "1          Vibrant purples and fiery pinks.  \n",
       "2  Fresh and cool summery greens and blues.  \n",
       "3    Vivid greens and blues, fresh harmony.  \n",
       "4       Vivid transition from red to green.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/par_dfdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc849617-4d26-4c76-b217-fb99a360890b",
   "metadata": {},
   "source": [
    "#### we want to build prompts for a palette-generation model: given a description, the model should output colors in hex format.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9177d465-ae63-47fc-92ed-baf1d659c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are a palette generator. Given a theme description, output ONLY a JSON array of exactly 4 hex colors (lowercase), no extra text.\\n\\nDescription: Fresh greens with a vibrant twist.\\nColors:', '[\"#c5d70f\", \"#4dd70f\", \"#0fd749\", \"#0fd7c1\"]')\n"
     ]
    }
   ],
   "source": [
    "def preprocess(row):\n",
    "    try:\n",
    "        cols = ast.literal_eval(row[\"colors\"])\n",
    "    except Exception:\n",
    "        cols = []\n",
    "    cols = [str(c).lower() for c in cols][:4] + [\"#000000\"] * max(0, 4 - len(cols))\n",
    "    prompt = (\n",
    "        \"You are a palette generator. Given a theme description, output ONLY a JSON array \"\n",
    "        \"of exactly 4 hex colors (lowercase), no extra text.\\n\\n\"\n",
    "        f\"Description: {row['resp']}\\nColors:\"\n",
    "    )\n",
    "    return prompt, json.dumps(cols)\n",
    "\n",
    "data = [preprocess(r) for _, r in df.iterrows()]\n",
    "train_data, val_data = data[:-2], data[-2:]\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b3e55-f2e3-4a77-9396-4f2be5fca193",
   "metadata": {},
   "source": [
    "#### exploring tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3f204c-aa82-4d78-8f8a-3cb07dec92e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<eos>', 0, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/gemma-3-270m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token,tokenizer.eos_token, tokenizer.pad_token_id, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "168f58f7-0e69-4c15-a545-2a3cd7a02d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74cb35d7-538e-4b21-a960-4dbb0d25c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bos_token <bos> 2\n",
      "eos_token <eos> 1\n",
      "unk_token <unk> 3\n",
      "pad_token <pad> 0\n",
      "boi_token <start_of_image> 255999\n",
      "eoi_token <end_of_image> 256000\n",
      "image_token <image_soft_token> 262144\n"
     ]
    }
   ],
   "source": [
    "for k,v in tokenizer.special_tokens_map.items():\n",
    "    print(k,v,tokenizer.convert_tokens_to_ids(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4cffd8a-ae87-4914-9032-13dda8c1c953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3ForCausalLM(\n",
       "  (model): Gemma3TextModel(\n",
       "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 640, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x Gemma3DecoderLayer(\n",
       "        (self_attn): Gemma3Attention(\n",
       "          (q_proj): Linear(in_features=640, out_features=1024, bias=False)\n",
       "          (k_proj): Linear(in_features=640, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=640, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=640, bias=False)\n",
       "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Gemma3MLP(\n",
       "          (gate_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=640, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "    (rotary_emb): Gemma3RotaryEmbedding()\n",
       "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=640, out_features=262144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, attn_implementation=\"eager\", torch_dtype=torch.float32\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d388dfb-a91f-4018-bade-272c33c6b646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e735ff63-1637-4e36-b02d-f7c93b8591bf",
   "metadata": {},
   "source": [
    "#### Tokenizing a sample prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9291b9f9-b451-4522-b94f-c498659f0adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 23391,   993]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"hello there\"\n",
    "test_inp = tokenizer(\n",
    "            test_prompt, truncation=True, max_length=100, return_tensors=\"pt\"\n",
    "        )\n",
    "test_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90856e84-1a50-48f6-a2b8-d7cabe030a2e",
   "metadata": {},
   "source": [
    "#### Feeding the tokens through the model â€” no labels yet, so we'll just get raw logits back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce9b710-ec0d-4670-8362-3911e75f08cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[-11.8900,   5.9166,  -0.8929,  ..., -11.9101, -11.9250, -11.8976],\n",
       "         [-20.3263,   5.4343,  -2.8779,  ..., -20.3377, -20.3426, -20.3376],\n",
       "         [-21.2356,   7.8493,  -3.0620,  ..., -21.2505, -21.2557, -21.2723]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_op = model(**test_inp)\n",
    "test_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a63ebd2-3aff-41ff-9974-ebb335c33071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 262144])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_op.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5daa2e-5bf9-4888-96c0-418c14d6b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 23391,   993]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_op = tokenizer(\n",
    "            test_prompt, truncation=True, max_length=100, return_tensors=\"pt\"\n",
    "        )[\"input_ids\"].clone()\n",
    "test_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477758cc-8b5e-447d-9c47-a8aefc866f12",
   "metadata": {},
   "source": [
    "#### Now let's add labels for supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44cfcb83-c7be-41a9-9633-96ab8ec9c6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(7.5639, grad_fn=<NllLossBackward0>), logits=tensor([[[-11.8900,   5.9166,  -0.8929,  ..., -11.9101, -11.9250, -11.8976],\n",
       "         [-20.3263,   5.4343,  -2.8779,  ..., -20.3377, -20.3426, -20.3376],\n",
       "         [-21.2356,   7.8493,  -3.0620,  ..., -21.2505, -21.2557, -21.2723]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_op_with_label = model(**test_inp,labels=test_op)\n",
    "test_op_with_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bc7d9-3965-4b09-8e61-e43525a33745",
   "metadata": {},
   "source": [
    "##### when labels are passed, we get loss\n",
    "##### so required inputs to model - input_ids, attention_mask, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3448dc69-39cb-4f2f-a6d1-b5aadea569a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 20])\n",
      "tensor([14625,   672,  8599, 46128,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "labels shape: torch.Size([2, 20])\n",
      "tensor([ -100,  -100,  8599, 46128,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n",
      "attention_mask shape: torch.Size([2, 20])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's simulate a batch of inputs and outputs.  \n",
    "# The goal: verify how padding, masking, and labels interact before doing real training.\n",
    "# when preparing a batch\n",
    "\n",
    "\n",
    "test_batch = [\n",
    "    {\"input\":\"who this\",\"output\":\"Bill Gates\"},\n",
    "    {\"input\":\"what do you do?\", \"output\": \"Run Microsoft\"}\n",
    "]\n",
    "\n",
    "\n",
    "# input to model: [input_tokens] + [output_tokens] +[pad,pad..]\n",
    "# labels: [-100,-100,...,output_tokens] + [-100,-100]\n",
    "# attention_mask: [1,1,......1,1,0,0]\n",
    "# setting tokens to -100 prevents model from generating loss for that \n",
    "# set all to maxlength\n",
    "max_len = 20\n",
    "\n",
    "input_ids_list = []\n",
    "labels_list = []\n",
    "attention_mask_list = []\n",
    "\n",
    "for ex in test_batch:\n",
    "    # 1. Tokenize input and output separately\n",
    "    input_enc = tokenizer(ex[\"input\"], add_special_tokens=False)\n",
    "    output_enc = tokenizer(\" \" + ex[\"output\"], add_special_tokens=False)\n",
    "\n",
    "    # 2. Concatenate for model input\n",
    "    ids = input_enc[\"input_ids\"] + output_enc[\"input_ids\"]\n",
    "    labels = [-100] * len(input_enc[\"input_ids\"]) + output_enc[\"input_ids\"]\n",
    "    attn = [1] * len(ids)  # attention on all real tokens\n",
    "\n",
    "    # 3. Pad to max_len\n",
    "    pad_len = max_len - len(ids)\n",
    "    ids += [tokenizer.pad_token_id] * pad_len\n",
    "    labels += [-100] * pad_len\n",
    "    attn += [0] * pad_len\n",
    "\n",
    "    input_ids_list.append(ids)\n",
    "    labels_list.append(labels)\n",
    "    attention_mask_list.append(attn)\n",
    "\n",
    "# 4. Convert to tensors\n",
    "input_ids = torch.tensor(input_ids_list, dtype=torch.long)\n",
    "labels = torch.tensor(labels_list, dtype=torch.long)\n",
    "attention_mask = torch.tensor(attention_mask_list, dtype=torch.long)\n",
    "\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(input_ids[0])\n",
    "print(\"labels shape:\", labels.shape)\n",
    "print(labels[0])\n",
    "print(\"attention_mask shape:\", attention_mask.shape)\n",
    "print(attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab2d1685-b59d-4f92-b8da-d595304e02e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(17.3345, grad_fn=<NllLossBackward0>), logits=tensor([[[-12.6587,  10.7030,  -1.6230,  ..., -12.7321, -12.7272, -12.6383],\n",
       "         [ -9.5866,  14.0531,   0.8286,  ...,  -9.6608,  -9.5785,  -9.5945],\n",
       "         [ -4.6152,  18.6236,   3.4610,  ...,  -4.6892,  -4.6904,  -4.6926],\n",
       "         ...,\n",
       "         [ -4.6603,  20.0995,   6.9139,  ...,  -4.7205,  -4.7245,  -4.7389],\n",
       "         [ -4.6376,  19.4029,   6.4830,  ...,  -4.6948,  -4.6971,  -4.7025],\n",
       "         [ -4.6061,  18.9384,   5.9728,  ...,  -4.6542,  -4.6637,  -4.6638]],\n",
       "\n",
       "        [[-12.1718,  16.4112,   5.4810,  ..., -12.3260, -12.2412, -12.1741],\n",
       "         [-13.5180,  24.3541,   0.4144,  ..., -13.7015, -13.7320, -13.7126],\n",
       "         [-12.9700,  21.1659,  -1.3985,  ..., -13.1612, -13.1265, -13.1250],\n",
       "         ...,\n",
       "         [ -9.4023,  16.0890,   4.9971,  ...,  -9.3868,  -9.4234,  -9.4143],\n",
       "         [ -9.4365,  15.1447,   4.8966,  ...,  -9.4318,  -9.4604,  -9.4549],\n",
       "         [ -9.2746,  15.0343,   4.1068,  ...,  -9.2787,  -9.3054,  -9.3045]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=DynamicCache(layers=[DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicSlidingWindowLayer, DynamicLayer]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=input_ids,labels=labels,attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d7ac067-dd48-4c9c-9882-7b99eae699ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,  23391,    993, 236761,    834,    607,    496,   2268,   3103,\n",
       "            529,   4481,   1601,    699,    786,    532,   1041,  32239, 236764,\n",
       "            564, 236789, 236757,   1771,    531,    577,  26804,    672,    528]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = model.generate(**test_inp,max_new_tokens=24,)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8844987f-1633-4a41-98be-294fb97ea1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<bos>hello there. so with a little bit of extra help from me and my girlfriend, I'm going to be explaining this in\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(op[0],\\\n",
    "                 skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e0b3d-ed36-4d51-b73b-16c4b8c8f59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
